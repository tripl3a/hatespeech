{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Classification on Hate Speech\n",
    "\n",
    "---\n",
    "\n",
    "__2nd Semester Data Science Master__  \n",
    "__Beuth University of Applied Sciences Berlin__\n",
    "\n",
    "__by Arndt, Ana, Christian, Ervin, Malte__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Content\n",
    "--- \n",
    "\n",
    "1. Preprocessing\n",
    "1. Baseline\n",
    "1. Pretrained Vectors\n",
    "1. Ensembles\n",
    "1. Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import sklearn.metrics as skm\n",
    "from os import chdir\n",
    "from sklearn import model_selection\n",
    "import skift\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "chdir(\"/home/arndt/git-reps/hatespeech/\")\n",
    "\n",
    "def load_train_test_data(train, test, test_labels, classname):\n",
    "\n",
    "    df_test = pd.merge(pd.read_csv(test),\n",
    "                       pd.read_csv(test_labels),\n",
    "                       how=\"inner\",\n",
    "                       on=\"id\")\n",
    "\n",
    "    df_train=pd.read_csv(train)\n",
    "\n",
    "    # data preperation\n",
    "\n",
    "    df_train=df_train[[\"id\",\"comment_text\",classname]]\n",
    "    df_train[\"comment_text\"]=df_train[\"comment_text\"].apply(str.replace,args=(\"\\n\",\" \"))\n",
    "    df_train[\"comment_text\"]=df_train[\"comment_text\"].apply(str.replace,args=(\"\\\"\",\"\"))\n",
    "\n",
    "    df_test[\"comment_text\"]=df_test[\"comment_text\"].apply(str.replace,args=(\"\\n\",\" \"))\n",
    "    df_test[\"comment_text\"]=df_test[\"comment_text\"].apply(str.replace,args=(\"\\\"\",\"\"))\n",
    "\n",
    "    X_train = pd.DataFrame(df_train.loc[:,\"comment_text\"])\n",
    "    y_train = df_train.loc[:,classname]\n",
    "    #-1 means the row wasn't used for scoring in the Kaggle competition\n",
    "    X_test = pd.DataFrame(df_test[df_test[classname]>-1].loc[:,\"comment_text\"]) \n",
    "    y_test = df_test[df_test[classname]>-1].loc[:,classname]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Preprocessing and Normalization  \n",
    "---  \n",
    "Improve the performance of the model applying some simple pre-processing  \n",
    "- Translation into English \n",
    "- Only ASCII characters (unidecode)\n",
    "- Remove special characters \n",
    "- Change Emojis to words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Google Translation API Requests\n",
    "---\n",
    "\n",
    "![Dashboard](google_dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Replace Characters  \n",
    "---  \n",
    "```py \n",
    "def replacetext(text):\n",
    "    for key, value in REPLACE_TO.items():\n",
    "        text = text.replace(key, value)\n",
    "    return text\n",
    "```\n",
    "\n",
    "```py \n",
    "REPLACE_TO = { \n",
    "':)':'happy' , ':(':'sad', ':P':'funny' ,  \n",
    "'@':'at' , '&':'and' , 'i\\'m':'i am' , 'don\\'t':'do not' , 'can\\'t':'can not' ,   \n",
    "'.':'' , ',':'' , ':':'', ';':'' , '!':'' , '\\'':' ' , '?':' ' , '(':' ', ')':' ' , '[':' ' , ']':' ' , '-':' ' , '#':' ' , '=':' ' , '+':' ' , '/':' ' , '\"':' ' ,   \n",
    "'0':' zero ' , '1':' one ' , '2':' two ' , '3':' three ', '3':' three ' , '4':' four ' , '5':' five ' ,'6' :' six ' , '7':' seven ' , '8':' eight ' , '9':' nine ' }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def score_preds(y_true, y_pred):\n",
    "    print(\"confusion matrix:\")\n",
    "    print(str(skm.confusion_matrix(y_true, y_pred)))\n",
    "    print(\"classification report:\")\n",
    "    print(str(skm.classification_report(y_true, y_pred)))\n",
    "    print(\"f1 macro: %0.4f\" % (skm.precision_recall_fscore_support(y_true, y_pred, average='macro')[2]))\n",
    "    print(\"f1 micro: %0.4f\" % (skm.precision_recall_fscore_support(y_true, y_pred, average='micro')[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Majority class classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[57888     0]\n",
      " [ 6090     0]]\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     57888\n",
      "          1       0.00      0.00      0.00      6090\n",
      "\n",
      "avg / total       0.82      0.90      0.86     63978\n",
      "\n",
      "f1 macro: 0.4750\n",
      "f1 micro: 0.9048\n"
     ]
    }
   ],
   "source": [
    "score_preds(y_test, np.zeros(y_test.shape)) #set all predictions to non-toxic (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* By only assigning all fitted values to the majority class we get a F1 score of 90%. \n",
    "* This is, because the test dataset is imbalanced and contains only 10% toxic comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Single skift model - baseline\n",
    "\n",
    "skift stands for scikit fasttext - scikit-learn wrappers for Python ([GitHub](https://github.com/shaypal5/skift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[54325  3563]\n",
      " [ 1218  4872]]\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96     57888\n",
      "          1       0.58      0.80      0.67      6090\n",
      "\n",
      "avg / total       0.94      0.93      0.93     63978\n",
      "\n",
      "f1 macro: 0.8143\n",
      "f1 micro: 0.9253\n",
      "f1 micro on training data: 0.9722\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test_data(\"data/train.csv\", \"data/test.csv\", \"data/test_labels.csv\", \"toxic\")\n",
    "\n",
    "skift_clf = skift.FirstObjFtClassifier()\n",
    "skift_clf.fit(X_train, y_train)\n",
    "preds = skift_clf.predict(X_test)\n",
    "score_preds(y_test, preds)\n",
    "print(\"f1 micro on training data: %0.4f\" % (skift_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single skift model - preprocessed data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[54324  3564]\n",
      " [ 1222  4868]]\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96     57888\n",
      "          1       0.58      0.80      0.67      6090\n",
      "\n",
      "avg / total       0.94      0.93      0.93     63978\n",
      "\n",
      "f1 macro: 0.8141\n",
      "f1 micro: 0.9252\n",
      "f1 micro on training data: 0.9722\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test_data(\"data/train_unidecode.csv\", \"data/test_unidecode.csv\", \"data/test_labels.csv\", \"toxic\")\n",
    "\n",
    "skift_clf = skift.FirstObjFtClassifier()\n",
    "skift_clf.fit(X_train, y_train)\n",
    "preds = skift_clf.predict(X_test)\n",
    "score_preds(y_test, preds)\n",
    "print(\"f1 micro on training data: %0.4f\" % (skift_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Single skift model - pretrained vectors\n",
    "\n",
    "fastText English Word Vectors trained on Wikipedia 2017, UMBC webbase corpus, and statmt.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[54738  3150]\n",
      " [ 1495  4595]]\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96     57888\n",
      "          1       0.59      0.75      0.66      6090\n",
      "\n",
      "avg / total       0.94      0.93      0.93     63978\n",
      "\n",
      "f1 macro: 0.8118\n",
      "f1 micro: 0.9274\n",
      "f1 micro on training data: 0.9684\n"
     ]
    }
   ],
   "source": [
    "skift_clf = skift.FirstObjFtClassifier(minn=3, maxn=3, pretrainedVectors=\"wiki-news-300d-1M-subword.vec\")\n",
    "skift_clf.fit(X_train, y_train)\n",
    "preds = skift_clf.predict(X_test)\n",
    "score_preds(y_test, preds)\n",
    "print(\"f1 micro on training data: %0.4f\" % (skift_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733432851735352\n",
      "0.9461546434494196\n",
      "0.7536945812807881\n",
      "0.5955624756714675\n"
     ]
    }
   ],
   "source": [
    "### For non-toxic ###\n",
    "# Recall = TP/(TP+FN)\n",
    "print(54771/(54771+1500))\n",
    "# Precision = TP/(TP+FP)\n",
    "print(54771/(54771+3117))\n",
    "\n",
    "### For toxic ###\n",
    "# Recall = TP/(TP+FN)\n",
    "print(4590/(4590+1500))\n",
    "# Precision = TP/(TP+FP)\n",
    "print(4590/(4590+3117))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Check common errors - false negatives\n",
    "\n",
    "What commonnalities have the false negatives? Check common errors …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "comp = pd.merge(pd.DataFrame({\"comment_text\" : X_test[\"comment_text\"].values, \"toxic_pred\" : preds}),\n",
    "                pd.concat([X_test, y_test], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1218, 3)\n",
      "                                          comment_text  toxic_pred  toxic\n",
      "8       arabs are committing genocide in iraq  but ...         0.0      1\n",
      "106      well  it sucks to have a university to be ...         0.0      1\n",
      "133       so  on the tenth anniversary of  nine   o...         0.0      1\n",
      "195           hey shithead  stop vandilizing articles          0.0      1\n",
      "279                   karl tearle is a mop haired twat         0.0      1\n"
     ]
    }
   ],
   "source": [
    "false_negatives = comp[(comp[\"toxic\"]==1) & (comp[\"toxic_pred\"]==0)]\n",
    "print(false_negatives.shape)\n",
    "false_negatives[\"comment_text\"].to_csv(\"data/false_negatives.txt\")\n",
    "print(false_negatives.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Check common errors - false positives\n",
    "\n",
    "What commonnalities have the false positives? Check common errors …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3563, 3)\n",
      "                                         comment_text  toxic_pred  toxic\n",
      "1                     dear god this site is horrible          1.0      0\n",
      "27  i will burn you to hell if you revoke my talk ...         1.0      0\n",
      "78          shameless canvass       hello  diannaa...         1.0      0\n",
      "79                          what the hell      justin         1.0      0\n",
      "87      buffoon synonyms     bozo  buffo  clown  c...         1.0      0\n"
     ]
    }
   ],
   "source": [
    "false_positives = comp[(comp[\"toxic\"]==0) & (comp[\"toxic_pred\"]==1)]\n",
    "print(false_positives.shape)\n",
    "false_positives[\"comment_text\"].to_csv(\"data/false_positives.txt\")\n",
    "print(false_positives.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Ensemble predictions\n",
    "\n",
    "Make predictions with a list of classifiers on a dataframe X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def ensemble_predict_proba(classifiers, X):\n",
    "    proba = [classifier.predict_proba(X) for classifier in classifiers]\n",
    "    mean = np.zeros(proba[0].shape)\n",
    "    for i in range(len(classifiers)):\n",
    "        mean = mean + proba[i]\n",
    "    mean = mean / float(len(classifiers))\n",
    "    return mean\n",
    "\n",
    "def ensemble_predict(classifiers, X):\n",
    "    kfold_proba = ensemble_predict_proba(classifiers, X)\n",
    "    kfold_labels = np.zeros(kfold_proba.shape[0]) #initialize array\n",
    "    kfold_labels[kfold_proba[:,0]<=kfold_proba[:,1]] = 1\n",
    "    return kfold_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Build multiple models using K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test proportion of this fold: 0.961\n",
      "Score on test proportion of this fold: 0.962\n",
      "Score on test proportion of this fold: 0.958\n",
      "Score on test proportion of this fold: 0.958\n",
      "Score on test proportion of this fold: 0.961\n",
      "Score on test proportion of this fold: 0.960\n",
      "Score on test proportion of this fold: 0.960\n",
      "Score on test proportion of this fold: 0.961\n",
      "Score on test proportion of this fold: 0.961\n",
      "Score on test proportion of this fold: 0.960\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test_data(\"data/train_unidecode.csv\", \"data/test_unidecode.csv\", \"data/test_labels.csv\", \"toxic\")\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True) #add variance through randomnization\n",
    "\n",
    "# build multiple models using k folds:\n",
    "kfold_clfs = list()\n",
    "for train_index, test_index in kfold.split(X_train):\n",
    "    clf = skift.FirstObjFtClassifier(minn=3, maxn=3, pretrainedVectors=\"data/wiki-news-300d-1M.vec\")\n",
    "    clf.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "    print(\"Score on test proportion of this fold: %0.3f\" % (clf.score(X_train.iloc[test_index], y_train.iloc[test_index])))\n",
    "    kfold_clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[54887  3001]\n",
      " [ 1431  4659]]\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96     57888\n",
      "          1       0.61      0.77      0.68      6090\n",
      "\n",
      "avg / total       0.94      0.93      0.93     63978\n",
      "\n",
      "f1 macro: 0.8194\n",
      "f1 micro: 0.9307\n"
     ]
    }
   ],
   "source": [
    "score_preds(y_test, ensemble_predict(kfold_clfs, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# StratifiedKFold\n",
    "\n",
    "* There are different strategies in creating a train set and test set split of your data. \n",
    "* If you want to keep the percentage for each class in each fold the same you want to use a stratified split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test_data(\"data/train_unidecode.csv\", \"data/test_unidecode.csv\", \"data/test_labels.csv\", \"toxic\")\n",
    "\n",
    "stkfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# build multiple models using k folds:\n",
    "stkfold_clfs = list()\n",
    "for train_index, test_index in stkfold.split(X=pd.DataFrame(df_train.loc[:,\"comment_text\"]), \n",
    "                                             y = df_train.loc[:,\"toxic\"]):\n",
    "    clf = skift.FirstObjFtClassifier(minn=3, maxn=3, pretrainedVectors=\"data/wiki-news-300d-1M.vec\")\n",
    "    clf.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "    clf.model.quantize()\n",
    "    print(\"Score on test proportion of this fold: %0.3f\" % (clf.score(X.iloc[test_index], y.iloc[test_index])))\n",
    "    stkfold_clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "score_preds(y_test, ensemble_predict(stkfold_clfs, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## KFold Conclusion\n",
    "\n",
    "The main reason we started to use KFold was that we didn't have the labeled test data at the beginning. But after we found the real test data on Kaggle, we used it.\n",
    "\n",
    "* k=10 slightly improved the score on the test set\n",
    "* k=5 scored worse than just a single model on all the training data \n",
    "* StratifiedKFold performed worse than the just KFold.\n",
    "\n",
    "I would not balance the data within the folds, as the data will not be balanced in a real-world example. Thus, the cross-validation score will not be represent the model performance well.\n",
    "\n",
    "Some ways to deal with imbalanced data is under- and over-sampling (e.g. SMOTE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Oversampling the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def oversample(X, y, p_oversample_size, p_oversample_ratio):\n",
    "    y_true_idx = y[y==1].index\n",
    "    y_false_idx = y[y==0].index\n",
    "    \n",
    "    true_frac = float(X.loc[y_true_idx,].count() / X.count())\n",
    "    false_frac = float(X.loc[y_false_idx,].count() / X.count())\n",
    "    oversample_true_frac = p_oversample_size * p_oversample_ratio / true_frac\n",
    "    oversample_false_frac = p_oversample_size * (1-p_oversample_ratio) / false_frac \n",
    "    \n",
    "    X_true =  X.loc[y_true_idx,].sample(frac=oversample_true_frac, replace=True)\n",
    "    X_false =  X.loc[y_false_idx,].sample(frac=oversample_false_frac, replace=True)\n",
    "\n",
    "    X_resampled = pd.concat([X_true, X_false])\n",
    "    y_resampled = y.loc[X_resampled.index]\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bagging ensemble - Oversampling w/ seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampling fraction: 0.0800 // score: 0.9342\n",
      "oversampling fraction: 0.0825 // score: 0.9351\n",
      "oversampling fraction: 0.0850 // score: 0.9233\n",
      "oversampling fraction: 0.0875 // score: 0.9355\n",
      "oversampling fraction: 0.0900 // score: 0.9357\n",
      "oversampling fraction: 0.0925 // score: 0.9353\n",
      "oversampling fraction: 0.0950 // score: 0.9333\n",
      "oversampling fraction: 0.0975 // score: 0.9141\n",
      "oversampling fraction: 0.1000 // score: 0.9354\n",
      "oversampling fraction: 0.1025 // score: 0.9192\n",
      "oversampling fraction: 0.1050 // score: 0.9235\n",
      "oversampling fraction: 0.1075 // score: 0.9196\n",
      "confusion matrix:\n",
      "[[56181  1707]\n",
      " [ 2477  3613]]\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.96     57888\n",
      "          1       0.68      0.59      0.63      6090\n",
      "\n",
      "avg / total       0.93      0.93      0.93     63978\n",
      "\n",
      "f1 macro: 0.7987\n",
      "f1 micro: 0.9346\n"
     ]
    }
   ],
   "source": [
    "# Oversampling different fractions and score\n",
    "\n",
    "oversample_clfs = list()\n",
    "\n",
    "for f in list(np.arange(0.08, 0.11, 0.0025)):\n",
    "    X_resampled, y_resampled = oversample(X_train, y_train, 1.25, f, seed)\n",
    "    skift_clf = skift.FirstObjFtClassifier(lr=0.2)\n",
    "    skift_clf.fit(X_resampled, y_resampled)\n",
    "    print(\"oversampling fraction: %0.4f // score: %0.4f\" % (f, skift_clf.score(X_test, y_test)))\n",
    "    oversample_clfs.append(skift_clf)\n",
    "\n",
    "score_preds(y_test, ensemble_predict(oversample_clfs, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Bagging ensemble - Oversampling w/o seed - 100 bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampling fraction: 0.0800 // score: 0.9200\n",
      "oversampling fraction: 0.0825 // score: 0.9362\n",
      "oversampling fraction: 0.0850 // score: 0.9376\n",
      "oversampling fraction: 0.0875 // score: 0.9179\n",
      "oversampling fraction: 0.0900 // score: 0.9224\n",
      "oversampling fraction: 0.0925 // score: 0.9356\n",
      "oversampling fraction: 0.0950 // score: 0.9195\n",
      "oversampling fraction: 0.0975 // score: 0.9128\n",
      "oversampling fraction: 0.1000 // score: 0.9161\n",
      "oversampling fraction: 0.1025 // score: 0.9117\n",
      "oversampling fraction: 0.1050 // score: 0.9194\n",
      "oversampling fraction: 0.1075 // score: 0.9133\n",
      "oversampling fraction: 0.0800 // score: 0.9364\n",
      "oversampling fraction: 0.0825 // score: 0.9238\n",
      "oversampling fraction: 0.0850 // score: 0.9172\n",
      "oversampling fraction: 0.0875 // score: 0.9376\n",
      "oversampling fraction: 0.0900 // score: 0.9367\n",
      "oversampling fraction: 0.0925 // score: 0.9196\n",
      "oversampling fraction: 0.0950 // score: 0.9259\n",
      "oversampling fraction: 0.0975 // score: 0.9382\n",
      "oversampling fraction: 0.1000 // score: 0.9381\n",
      "oversampling fraction: 0.1025 // score: 0.9137\n",
      "oversampling fraction: 0.1050 // score: 0.9241\n",
      "oversampling fraction: 0.1075 // score: 0.9206\n",
      "oversampling fraction: 0.0800 // score: 0.9347\n",
      "oversampling fraction: 0.0825 // score: 0.9215\n",
      "oversampling fraction: 0.0850 // score: 0.9257\n",
      "oversampling fraction: 0.0875 // score: 0.9255\n",
      "oversampling fraction: 0.0900 // score: 0.9243\n",
      "oversampling fraction: 0.0925 // score: 0.9310\n",
      "oversampling fraction: 0.0950 // score: 0.9226\n",
      "oversampling fraction: 0.0975 // score: 0.9138\n",
      "oversampling fraction: 0.1000 // score: 0.9229\n",
      "oversampling fraction: 0.1025 // score: 0.9106\n",
      "oversampling fraction: 0.1050 // score: 0.9162\n",
      "oversampling fraction: 0.1075 // score: 0.9215\n",
      "oversampling fraction: 0.0800 // score: 0.9119\n",
      "oversampling fraction: 0.0825 // score: 0.9374\n",
      "oversampling fraction: 0.0850 // score: 0.9239\n",
      "oversampling fraction: 0.0875 // score: 0.9325\n",
      "oversampling fraction: 0.0900 // score: 0.9374\n",
      "oversampling fraction: 0.0925 // score: 0.9375\n",
      "oversampling fraction: 0.0950 // score: 0.9146\n",
      "oversampling fraction: 0.0975 // score: 0.9094\n",
      "oversampling fraction: 0.1000 // score: 0.9016\n",
      "oversampling fraction: 0.1025 // score: 0.9235\n",
      "oversampling fraction: 0.1050 // score: 0.9227\n",
      "oversampling fraction: 0.1075 // score: 0.9346\n",
      "oversampling fraction: 0.0800 // score: 0.9365\n",
      "oversampling fraction: 0.0825 // score: 0.9361\n",
      "oversampling fraction: 0.0850 // score: 0.9082\n",
      "oversampling fraction: 0.0875 // score: 0.9364\n",
      "oversampling fraction: 0.0900 // score: 0.9373\n",
      "oversampling fraction: 0.0925 // score: 0.9367\n",
      "oversampling fraction: 0.0950 // score: 0.9204\n",
      "oversampling fraction: 0.0975 // score: 0.9077\n",
      "oversampling fraction: 0.1000 // score: 0.9181\n",
      "oversampling fraction: 0.1025 // score: 0.9236\n",
      "oversampling fraction: 0.1050 // score: 0.9374\n",
      "oversampling fraction: 0.1075 // score: 0.9128\n",
      "oversampling fraction: 0.0800 // score: 0.9365\n",
      "oversampling fraction: 0.0825 // score: 0.9201\n",
      "oversampling fraction: 0.0850 // score: 0.9344\n",
      "oversampling fraction: 0.0875 // score: 0.9163\n",
      "oversampling fraction: 0.0900 // score: 0.9370\n",
      "oversampling fraction: 0.0925 // score: 0.9209\n",
      "oversampling fraction: 0.0950 // score: 0.9133\n",
      "oversampling fraction: 0.0975 // score: 0.9264\n",
      "oversampling fraction: 0.1000 // score: 0.9254\n",
      "oversampling fraction: 0.1025 // score: 0.9127\n",
      "oversampling fraction: 0.1050 // score: 0.9118\n",
      "oversampling fraction: 0.1075 // score: 0.9366\n",
      "oversampling fraction: 0.0800 // score: 0.9373\n",
      "oversampling fraction: 0.0825 // score: 0.9230\n",
      "oversampling fraction: 0.0850 // score: 0.9371\n",
      "oversampling fraction: 0.0875 // score: 0.9203\n",
      "oversampling fraction: 0.0900 // score: 0.9240\n",
      "oversampling fraction: 0.0925 // score: 0.9349\n",
      "oversampling fraction: 0.0950 // score: 0.9214\n",
      "oversampling fraction: 0.0975 // score: 0.9253\n",
      "oversampling fraction: 0.1000 // score: 0.9302\n",
      "oversampling fraction: 0.1025 // score: 0.9339\n",
      "oversampling fraction: 0.1050 // score: 0.9218\n",
      "oversampling fraction: 0.1075 // score: 0.9145\n",
      "oversampling fraction: 0.0800 // score: 0.9114\n",
      "oversampling fraction: 0.0825 // score: 0.9384\n",
      "oversampling fraction: 0.0850 // score: 0.9218\n",
      "oversampling fraction: 0.0875 // score: 0.9148\n",
      "oversampling fraction: 0.0900 // score: 0.9287\n",
      "oversampling fraction: 0.0925 // score: 0.9238\n",
      "oversampling fraction: 0.0950 // score: 0.9152\n",
      "oversampling fraction: 0.0975 // score: 0.9250\n",
      "oversampling fraction: 0.1000 // score: 0.9115\n",
      "oversampling fraction: 0.1025 // score: 0.9342\n",
      "oversampling fraction: 0.1050 // score: 0.9286\n",
      "oversampling fraction: 0.1075 // score: 0.9162\n",
      "confusion matrix:\n",
      "[[54913  2975]\n",
      " [ 1444  4646]]\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96     57888\n",
      "          1       0.61      0.76      0.68      6090\n",
      "\n",
      "avg / total       0.94      0.93      0.93     63978\n",
      "\n",
      "f1 macro: 0.8195\n",
      "f1 micro: 0.9309\n"
     ]
    }
   ],
   "source": [
    "# Oversampling different fractions and score\n",
    "\n",
    "oversample_clfs = list()\n",
    "\n",
    "for i in range(8):\n",
    "    for f in list(np.arange(0.08, 0.11, 0.0025)):\n",
    "        X_resampled, y_resampled = oversample(X_train, y_train, 1.25, f)\n",
    "        skift_clf = skift.FirstObjFtClassifier(lr=0.2)\n",
    "        skift_clf.fit(X_resampled, y_resampled)\n",
    "        skift_clf.model.quantize()\n",
    "        print(\"oversampling fraction: %0.4f // score: %0.4f\" % (f, skift_clf.score(X_test, y_test)))\n",
    "        oversample_clfs.append(skift_clf)\n",
    "\n",
    "score_preds(y_test, ensemble_predict(oversample_clfs, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Result comparison\n",
    "**Single skift model - baseline**  \n",
    "``\n",
    "confusion matrix:  \n",
    "[[54325  3563]             f1 macro: 0.8143\n",
    " [ 1218  4872]]            f1 micro: 0.9253\n",
    "``\n",
    "\n",
    "**Single skift model - preprocessed data**  \n",
    "``\n",
    "confusion matrix:  \n",
    "[[54324  3564]             f1 macro: 0.8141\n",
    " [ 1222  4868]]            f1 micro: 0.9252\n",
    "``\n",
    "\n",
    "**Single skift model - pretrained vectors**  \n",
    "``\n",
    "confusion matrix:  \n",
    "[[54738  3150]             f1 macro: 0.8118  \n",
    " [ 1495  4595]]            f1 micro: 0.9274\n",
    "``\n",
    "\n",
    "**Bagging ensemble - Oversampling with seed - 8 bags**   \n",
    "``\n",
    "confusion matrix:  \n",
    "[[56181  1707]             f1 macro: 0.7987     \n",
    " [ 2477  3613]]            f1 micro: 0.9346\n",
    "``\n",
    "\n",
    "**Bagging ensemble - Oversampling without seed - 96 bags**  \n",
    "``\n",
    "confusion matrix:  \n",
    "[[54913  2975]             f1 macro: 0.8195\n",
    " [ 1444  4646]]            f1 micro: 0.9309\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identity hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[63026   240]\n",
      " [  479   233]]\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     63266\n",
      "          1       0.49      0.33      0.39       712\n",
      "\n",
      "avg / total       0.99      0.99      0.99     63978\n",
      "\n",
      "f1 macro: 0.6938\n",
      "f1 micro: 0.9888\n",
      "f1 micro on training data: 0.9934\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test_data(\"data/train_unidecode.csv\", \"data/test_unidecode.csv\", \"data/test_labels.csv\", \"identity_hate\")\n",
    "\n",
    "skift_clf = skift.FirstObjFtClassifier()\n",
    "skift_clf.fit(X_train, y_train)\n",
    "\n",
    "preds = skift_clf.predict(X_test)\n",
    "score_preds(y_test, preds)\n",
    "\n",
    "print(\"f1 micro on training data: %0.4f\" % (skift_clf.score(X_train, y_train))) #overfitted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conslusion\n",
    "\n",
    "* Random results - due to initialization of neural net's weights - make result comparison difficult\n",
    "* Ensembles to stabilize the results\n",
    "* Really unclear on how some parameters improve the score i.e. pretrained vectors\n",
    "* Usage within scikit-learn difficult, if you don't have numeric predictors \n",
    "\n",
    "## More ideas\n",
    "\n",
    "* GridSearch on \"good\" fastText hyperparameters\n",
    "* Generate many models and persist one that scores high\n",
    "* Continousliy improve the persisted model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Tfidf Method using Scikit vectorizer\n",
    "\n",
    "* This method was inspired by one of the Kaggle Competitors who used sklearn to implement a Logistic regression with words & char n grams. And his work achieved a better score only to mention that it doesn't use fastText at all for it's implementation.\n",
    "\n",
    "link : https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams/code \n",
    "\n",
    "* A few edits were made to create the following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CV score for class toxic is 0.9567386963649188\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import chdir, path\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "chdir(path.dirname(path.abspath('__file__')))\n",
    "train = pd.read_csv('data/train.csv').fillna(' ')\n",
    "test = pd.read_csv('data/test.csv').fillna(' ')\n",
    "\n",
    "df_test = pd.merge(pd.read_csv(\"data/test.csv\"),\n",
    "                   pd.read_csv(\"data/test_labels.csv\"),\n",
    "                   how=\"inner\",\n",
    "                   on=\"id\")\n",
    "\n",
    "#y_test = df_test[df_test[\"toxic\"]>-1].loc[:,\"toxic\"]\n",
    "train_text = train['comment_text']\n",
    "test_text = pd.DataFrame(df_test[df_test[\"toxic\"]>-1].loc[:,\"comment_text\"])[\"comment_text\"]\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=50000)\n",
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "test_char_features = char_vectorizer.transform(test_text)\n",
    "\n",
    "train_features = hstack([train_char_features, train_word_features])\n",
    "test_features = hstack([test_char_features, test_word_features])\n",
    "\n",
    "scores = []\n",
    "scores_test = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in [\"toxic\"]:\n",
    "\n",
    "    train_target = train[class_name]\n",
    "    test_target = df_test[df_test[class_name]>-1].loc[:,\"toxic\"]\n",
    "\n",
    "    classifier_test = LogisticRegression(C=0.1, solver='sag')\n",
    "    classifier_test.fit(train_features, train_target)\n",
    "\n",
    "    cv_score_test = np.mean(cross_val_score(classifier_test, test_features, test_target, cv=3, scoring='roc_auc'))\n",
    "    scores_test.append(cv_score_test)\n",
    "    print('Test CV score for class {} is {}'.format(class_name, cv_score_test))\n",
    "\n",
    "    #classifier.fit(train_features, train_target)\n",
    "    #submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "#print('Total CV score is {}'.format(np.mean(scores)))\n",
    "#print('Total Test CV score is {}'.format(np.mean(scores_test)))\n",
    "\n",
    "#submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import chdir, path\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "chdir(path.dirname(path.abspath('__file__')))\n",
    "train = pd.read_csv('data/train.csv').fillna(' ')\n",
    "test = pd.read_csv('data/test.csv').fillna(' ')\n",
    "\n",
    "df_test = pd.merge(pd.read_csv(\"data/test.csv\"),\n",
    "                   pd.read_csv(\"data/test_labels.csv\"),\n",
    "                   how=\"inner\",\n",
    "                   on=\"id\")\n",
    "\n",
    "#y_test = df_test[df_test[\"toxic\"]>-1].loc[:,\"toxic\"]\n",
    "train_text = train['comment_text']\n",
    "test_text = pd.DataFrame(df_test[df_test[\"identity_hate\"]>-1].loc[:,\"comment_text\"])[\"comment_text\"]\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=50000)\n",
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "test_char_features = char_vectorizer.transform(test_text)\n",
    "\n",
    "train_features = hstack([train_char_features, train_word_features])\n",
    "test_features = hstack([test_char_features, test_word_features])\n",
    "\n",
    "scores = []\n",
    "scores_test = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in [\"identity_hate\"]:\n",
    "\n",
    "    train_target = train[class_name]\n",
    "    test_target = df_test[df_test[class_name]>-1].loc[:,\"identity_hate\"]\n",
    "\n",
    "    classifier_test = LogisticRegression(C=0.1, solver='sag')\n",
    "    classifier_test.fit(train_features, train_target)\n",
    "\n",
    "    cv_score_test = np.mean(cross_val_score(classifier_test, test_features, test_target, cv=3, scoring='roc_auc'))\n",
    "    scores_test.append(cv_score_test)\n",
    "    print('Test CV score for class {} is {}'.format(class_name, cv_score_test))\n",
    "\n",
    "    #classifier.fit(train_features, train_target)\n",
    "    #submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "#print('Total CV score is {}'.format(np.mean(scores)))\n",
    "#print('Total Test CV score is {}'.format(np.mean(scores_test)))\n",
    "\n",
    "#submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
